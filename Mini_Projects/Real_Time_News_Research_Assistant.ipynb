{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uI4N8pOhlFXv",
        "outputId": "a566b556-ede8-42b5-f9bd-0982b258d05b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.6/426.6 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.1/489.1 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.9/234.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires google-auth==2.43.0, but you have google-auth 2.47.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain-community duckduckgo-search langchain-google-genai\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U ddgs"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBoDv5iSvWVv",
        "outputId": "649b7b03-c00f-4d14-e9cd-f872ce30c79d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ddgs\n",
            "  Downloading ddgs-9.10.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from ddgs) (8.3.1)\n",
            "Requirement already satisfied: primp>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from ddgs) (0.15.0)\n",
            "Requirement already satisfied: lxml>=4.9.4 in /usr/local/lib/python3.12/dist-packages (from ddgs) (6.0.2)\n",
            "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.28.1)\n",
            "Collecting fake-useragent>=2.2.0 (from ddgs)\n",
            "  Downloading fake_useragent-2.2.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.16.0)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.2.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.3.0)\n",
            "Collecting socksio==1.* (from httpx[brotli,http2,socks]>=0.28.1->ddgs)\n",
            "  Downloading socksio-1.0.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.1.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.15.0)\n",
            "Downloading ddgs-9.10.0-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fake_useragent-2.2.0-py3-none-any.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading socksio-1.0.0-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: socksio, fake-useragent, ddgs\n",
            "Successfully installed ddgs-9.10.0 fake-useragent-2.2.0 socksio-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_community.tools import DuckDuckGoSearchResults, DuckDuckGoSearchRun\n",
        "from langchain_core.runnables import RunnableBranch, RunnableLambda, RunnableParallel\n",
        "from google.colab import userdata\n",
        "from langchain.agents import create_agent\n",
        "from datetime import datetime\n",
        "from langchain_core.tools import tool\n",
        "import requests\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite\",google_api_key=userdata.get('Assignments'))\n",
        "\n",
        "print(\"Libraries and API KEY Integrated Succesfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wF9pMoSAmqk5",
        "outputId": "a3f2b855-fd46-411f-bbed-f87ab987c656"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries and API KEY Integrated Succesfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Intent Extraction**"
      ],
      "metadata": {
        "id": "fCwaWDHfnvd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "intent_prompt = PromptTemplate(input_variables=[\"query\"]\n",
        "    template=\"\"\"\n",
        "You are a PRO news assistant.\n",
        "\n",
        "From the user query below, extract:\n",
        "1. topic : short phrase\n",
        "2. Information Type : one of [headlines, deep_dive, mixed]\n",
        "\n",
        "Return strictly in this format:\n",
        "topic: <topic>\n",
        "type: <headlines | deep_dive | mixed>\n",
        "\n",
        "User Query:\n",
        "{query}\n",
        "\"\"\",\n",
        "\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "TkBPm4Gtnstu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DuckDuckGo Search Tool**"
      ],
      "metadata": {
        "id": "_BkhfiuAoQXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_tool = DuckDuckGoSearchResults(output_format=\"list\")\n"
      ],
      "metadata": {
        "id": "gpfOK_XKoPcW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def intent_ext(text):\n",
        "    lines = text.splitlines()\n",
        "    topic = lines[0].split(\"topic:\")[1].strip()\n",
        "    info_type = lines[1].split(\"type:\")[1].strip()\n",
        "    return {\"topic\": topic, \"type\": info_type}\n",
        "def context_ext(results, max_items=5):\n",
        "    context = \"\"\n",
        "    for i, item in enumerate(results[:max_items], start=1):\n",
        "        context += (\n",
        "            f\"Headline {i}: {item['title']}\\n\"\n",
        "            f\"Description: {item['snippet']}\\n\"\n",
        "            f\"Link: {item['link']}\\n\\n\"\n",
        "        )\n",
        "    return context\n"
      ],
      "metadata": {
        "id": "_Ye4c8nUwkz2"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Headline Prompt\n",
        "headlines_prompt = PromptTemplate(input_variables=[\"context\"],\n",
        "    template=\"\"\"\n",
        "You are a PRO news assistant.\n",
        "\n",
        "Given the following news articles, generate 3–5 concise bullet-point headlines.\n",
        "Each bullet:\n",
        "1)One sentence\n",
        "2)Brief explanation\n",
        "3)Optionally include the most relevant link in brackets\n",
        "\n",
        "Articles:\n",
        "{context}\n",
        "\"\"\",\n",
        "\n",
        ")\n",
        "# Deep_Dive Prompt\n",
        "deep_dive_prompt = PromptTemplate(input_variables=[\"context\"],\n",
        "    template=\"\"\"\n",
        "You are a PRO news research assistant.\n",
        "\n",
        "Using the articles below, write a clear, beginner-friendly summary (2–4 short paragraphs)\n",
        "explaining:\n",
        "1)What is happening\n",
        "2)Why it matters\n",
        "3)Key dates, numbers, or names\n",
        "\n",
        "No fluff. Be factual and clear.\n",
        "\n",
        "Articles:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        ")\n",
        "# Mixed Prompt\n",
        "mixed_prompt = PromptTemplate(input_variables=[\"context\"],\n",
        "    template=\"\"\"\n",
        "You are a PRO news assistant.\n",
        "\n",
        "First, generate 3 short bullet-point headlines.\n",
        "Then, write a brief 1–2 paragraph summary combining the key ideas.\n",
        "\n",
        "Articles:\n",
        "{context}\n",
        "\"\"\"\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "uyWoLhFsxGes"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cnbvq8QZ4MY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intent_chain = intent_prompt | llm | StrOutputParser()\n",
        "headlines_chain = headlines_prompt | llm | StrOutputParser()\n",
        "deep_dive_chain = deep_dive_prompt | llm | StrOutputParser()\n",
        "mixed_chain = mixed_prompt | llm | StrOutputParser()\n",
        "runnable_branch = RunnableBranch(\n",
        "    (lambda x: x[\"type\"] == \"headlines\", headlines_chain),\n",
        "    (lambda x: x[\"type\"] == \"deep_dive\", deep_dive_chain),\n",
        "    (lambda x: x[\"type\"] == \"mixed\", mixed_chain),\n",
        "    mixed_chain\n",
        ")\n"
      ],
      "metadata": {
        "id": "OANYMkCgzNRf"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = input(\"Enter your query: \")\n",
        "def news_assistant(query):\n",
        "   intent_text = intent_chain.invoke({\"query\": query})\n",
        "   intent = intent_ext(intent_text)\n",
        "   results = search_tool.invoke(intent[\"topic\"])\n",
        "   context = context_ext(results)\n",
        "   response = runnable_branch.invoke({\n",
        "       \"context\": context,\n",
        "       \"type\": intent[\"type\"]\n",
        "   })\n",
        "   return response\n",
        "print(news_assistant(user_query))\n",
        "print(news_assistant(\"Current inflation news in India\"))\n",
        "print(news_assistant(\"Recent breakthroughs in cancer research\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "K2P-GBxI0nzu",
        "outputId": "e4a8acb6-d25d-4227-83ab-1d075a0dd426"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your query: latest news in AI Industry\n",
            "Here are 3 concise bullet-point headlines based on the provided articles:\n",
            "\n",
            "*   **AI Market Poised for Explosive Growth:** Projections indicate the global AI market could reach over $1.7 trillion by 2032, with significant annual growth rates and a booming chip sector. [https://www.fortunebusinessinsights.com/industry-reports/artificial-intelligence-market-100114]\n",
            "*   **AI's Economic Impact and Future Questions:** The rapid expansion of AI is driving tech industry growth and economic development, but concerns about a potential bubble and the responsible guidance of this transformation are surfacing. [https://www.pbs.org/newshour/show/whats-next-for-ai-and-has-its-explosive-growth-in-2025-created-a-bubble]\n",
            "*   **AI Set to Reshape Industries, Focus on Human Well-being:** Experts agree AI will fundamentally transform various sectors, with the critical challenge being how to steer this evolution to ensure human security and well-being. [https://www.forbes.com/sites/chuckbrooks/2026/01/02/the-next-great-transformation-how-ai-will-reshape-industries-and-itself/]\n",
            "Here are 3 concise bullet-point headlines:\n",
            "\n",
            "*   **India's Inflation Dips to Multi-Year Lows:** Consumer price inflation eased to 0.71% in November 2025, marking the lowest rate since June 2017 and falling below the Reserve Bank of India's target. [https://tradingeconomics.com/india/inflation-cpi]\n",
            "*   **Economic Growth Accelerates Amidst Low Inflation:** India's economy is projected to end 2025 on a strong note with robust GDP growth and a significant drop in inflation. [https://economictimes.indiatimes.com/news/economy/indicators/india-set-to-end-2025-on-strong-economic-footing-with-high-growth-low-inflation-govt/articleshow/126245322.cms]\n",
            "*   **November CPI Inflation Shows Slight Increase:** The year-on-year inflation rate based on the All India Consumer Price Index rose to 0.71% in November 2025, a 46-basis point increase from the previous month. [https://mospi.gov.in/uploads/latestReleases/latest_release_1765535195348_9e92bc5c-fe73-44ac-bfb8-d587b1f59218_Press_Release_CPI_November_2025.pdf]\n",
            "Here are 3 short bullet-point headlines:\n",
            "\n",
            "*   Cancer Research Sees Major Advances: New Treatments and Exhibitions Emerge\n",
            "*   Scientists Uncover Promising Cancer Breakthroughs, Including New Therapies\n",
            "*   Innovation in Cancer Fight: From Lung Cancer Patterns to Aggressive Cancer Treatments\n",
            "\n",
            "**Summary:**\n",
            "\n",
            "Recent developments in cancer research highlight significant progress on multiple fronts. Breakthrough Cancer Research has launched a groundbreaking exhibition, \"Cancer Revolution: Science, Innovation…,\" underscoring the ongoing commitment to advancing the field. Simultaneously, Australian scientists have announced a discovery of a new treatment for aggressive cancers, offering renewed hope.\n",
            "\n",
            "Further innovation is evident with lung cancer researchers identifying breakthrough patterns that predict treatment success, enabling more targeted and effective therapies. These advancements, including explorations into vaccines and liquid biopsies, represent a crucial step forward in the fight against various forms of cancer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7-DfiUKO10ml"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}